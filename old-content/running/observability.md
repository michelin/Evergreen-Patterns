---
title: "Observability"
date: 2022-04-12T16:11:50+02:00
draft: false
categories:
- running
description: "I proactively set up my golden signals and SLIs in order to reduce time to detect situations"
interact_with: "unbalanced_capacities, snowball_effect, reactive_operations, hero_problem_solving, unmastered_systems, untracked_operations"
---

# Main Purpose

The purpose of Observability is to better understand the system’s behavior and state to reduce both the time to detect an issue and the time to fix the issue. To be fully customer centric and secure the Quality of Service, the system to consider for observability, is the one supporting business capabilities or processes from an End to End and Full Stack perspective, including critical dependencies. Therfore, it is likely that the observability will factor in various applications, flows, components, and layers ranging from middlewares to infrastructure.

Observability can be built by collecting and analyzing different types of information such as metrics, logs and traces.

Defining Service Level Indicators and Service Level Objectives helps to detect situations by focusing on key elements.

Observability makes monitoring more effective and troubleshooting easier by providing answers to many questions. This is especially true for modern architectures such as distributed systems that have a much higher number of components, and therefore a potential higher number and type of failure.

# How it works

The first step is to define what elements need to be able to tell if the system is working well or not, and if it is not working, where the issue is. Using a well-designed and populated CMDB (Configuration Management Data Base) or a FMEA tool (Failure Mode Effect Analysis) may be very useful.

There are many types of data available (also known as telemetry):

* Logs: a log is a text record of events that happened and includes timestamps and additional information (what happened, some contextual information, metadata, …).

* Metrics: a metric is a numerical value recorded at a specific time and includes one or more “dimensions” such as application name, host name, … they are often aggregated over a period of time.

* Traces: a trace exposes the execution path through a system; it is like an after-the-fact Gantt chart that represents all the things an application transaction spent its time on – all ordered over time from beginning to end.



Some of those elements are provided by the operating systems or middlewares, but others must be generated by your systems.

It is therefore important to define the elements you need to generate to be able to monitor the performance of your systems or to troubleshoot them.

As an example, SRE’s Golden Signals are four key metrics than can be used to monitor the health of a system:

* Latency: the time it takes to serve a request

* Traffic: the total number of requests processed

* Errors: the number of requests that fail

* Saturation: the load on the system (network and servers)



You can of course define your own Service Level Indicators that would be closer to the business.

It is important to keep things simple: complex indicators are harder to reason about.



Once those elements are identified, they need to be generated by the systems, collected, ingested, and analyzed.

Tools can be used to detect issues and trigger alerts or launch scripts to fix the issue (self-healing).

You can even use tools such as machine learning to detect anomalies and accelerate the response, or even better to prevent the incident. 
